{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and organize data\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Define a function to read and process the file\n",
    "def read_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Initialize variables to store data\n",
    "    papers = []\n",
    "    current_paper = {}\n",
    "    references = []\n",
    "\n",
    "    # Process each line in the file\n",
    "    for line in lines:\n",
    "        if line.startswith('#*'):\n",
    "            current_paper['title'] = line[2:].strip()\n",
    "        elif line.startswith('#@'):\n",
    "            current_paper['authors'] = line[2:].strip().split(',')\n",
    "        elif line.startswith('#t'):\n",
    "            current_paper['year'] = int(line[2:].strip())\n",
    "        elif line.startswith('#c'):\n",
    "            current_paper['venue'] = line[2:].strip()\n",
    "        elif line.startswith('#index'):\n",
    "            current_paper['index_id'] = int(line[6:].strip())\n",
    "        elif line.startswith('#%'):\n",
    "            references.append(int(line[2:].strip()))\n",
    "        elif line.startswith('#!'):\n",
    "            current_paper['abstract'] = line[2:].strip()\n",
    "        elif line.strip() == '' and current_paper:\n",
    "            current_paper['references'] = references\n",
    "            papers.append(current_paper)\n",
    "            current_paper = {}\n",
    "            references = []\n",
    "\n",
    "    # Handle the last paper\n",
    "    if current_paper:\n",
    "        current_paper['references'] = references\n",
    "        papers.append(current_paper)\n",
    "\n",
    "    return pd.DataFrame(papers)\n",
    "\n",
    "def save_to_file(df, file_path):\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "    \n",
    "input_file_path = 'raw_data.txt'  \n",
    "output_file_path = 'data.csv'  \n",
    "df = read_data(input_file_path)\n",
    "save_to_file(df, output_file_path)\n",
    "with open('data.pkl', 'wb') as file:\n",
    "    pickle.dump(df, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges from the DataFrame\n",
    "for row in range(df.shape[0]):\n",
    "    r = df.loc[row]\n",
    "    G.add_node(r['index_id'], title=r['title'])  # Add paper as node\n",
    "    for cited in r['references']: # convert string back to list\n",
    "        G.add_edge(r['index_id'], cited)  # Add citation edge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph in GraphML format\n",
    "nx.write_graphml(G, 'Cleaned Data and Graph/citation_network.graphml')\n",
    "\n",
    "# Save the graph in GEXF format\n",
    "nx.write_gexf(G, 'Cleaned Data and Graph/citation_network.gexf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "if isinstance(df['authors'].iloc[0], str):\n",
    "    df['authors'] = df['authors'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "def build_author_network(df):\n",
    "    \"\"\"\n",
    "    Build a network of authors, where two authors are connected if they co-authored a paper.\n",
    "\n",
    "    df: DataFrame with author and paper information.\n",
    "    return: A NetworkX graph representing the author network.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for authors in df['authors']:\n",
    "        # Create edges between all pairs of co-authors\n",
    "        for author1, author2 in itertools.combinations(authors, 2):\n",
    "            if G.has_edge(author1, author2):\n",
    "                # Increase weight if authors have co-authored multiple papers\n",
    "                G[author1][author2]['weight'] += 1\n",
    "            else:\n",
    "                # Add new edge with weight 1\n",
    "                G.add_edge(author1, author2, weight=1)\n",
    "\n",
    "    return G\n",
    "\n",
    "# Example \n",
    "author_network = build_author_network(df)\n",
    "nx.write_graphml(author_network, 'Cleaned Data and Graph/author_network.graphml')\n",
    "\n",
    "# Save the graph in GEXF format\n",
    "nx.write_gexf(author_network, 'Cleaned Data and Graph/author_network.gexf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casestudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
